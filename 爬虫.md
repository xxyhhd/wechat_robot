爬虫分类：　通用爬虫、聚焦爬虫

１、定位ＵＲＬ
２、

## urllib

###实例一
```python
import urllib.request
import urllib.parse  # 解决参数配置问题

url = 'http://www.baidu.com/s?'
data = {
    'wd': '美女',
    'pass': '性别'
}

urllib.request.urlretrieve(url=url, filename='baidu.html')　　# 保存到本地

data1 = urllib.parse.urlencode(data)
url = url + data1

print(url)
```

###实例二
```python
import urllib.request

url = 'http://www.baidu.com'
response = urllib.request.urlopen(url=url)
print(type(response))  # 获取类型, <class 'http.client.HTTPResponse'>
print(response.getcode())  # 　获取状态码, 200
print(response.geturl()) # 获取ＵＲＬ
print(response.getheaders())  # 获取头信息

# 编码：object-->字节　encode：对字典类型，　quote：　对单个字符串
# 解码：字节-->object  decode：对字典类型， unquote：　对单个字符串
print(response.read().decode('utf-8'))  # utf-8解码,获取页面源码，readline()读取一行，readlines(num)读取多行
```

###实例三，修改头信息
```python
import urllib.request

url = 'http://www.baidu.com'
headers = {
    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'
}

request = urllib.request.Request(url=url, headers=headers)  # request 相当于url, 可以加其他参数
respones = urllib.request.urlopen(request)
print(respones.getcode())
```

###爬起豆瓣电影
```python
import urllib.request
import urllib.parse
import json


def get_tag():
    url = 'https://movie.douban.com/j/search_tags?type=movie&source='
    respones = urllib.request.urlopen(url=url)
    content = respones.read().decode('utf-8')
    my_json = json.loads(content)
    info = '  '.join(my_json['tags'])
    print('可选电影种类：', info)
    return my_json['tags']


def create_request(a):
    tag = str(input('请输入查询的电影类型：'))
    cate = urllib.parse.quote(tag)
    num = int(input('请输入你需要查询的数量：'))
    page = num//20
    remainder = num % 20
    print('{0:^5}\t{1:{3}^３0}\t{2:^８}'.format('排名', '电影名称', '评分', chr(12288)))
    for x in range(page):
        data = {
            'page_start': x*20,
        }
        data = data = urllib.parse.urlencode(data)
        url = 'https://movie.douban.com/j/search_subjects?type=movie&page_limit=20&sort=rank&' + \
            'tag=' + cate + '&' + data
        respones = urllib.request.urlopen(url=url)
        content = respones.read().decode('utf-8')
        my_json = json.loads(content)
        count = x*20
        for move in my_json['subjects']:
            count += 1
            print('{0:^5}\t{1:{3}^３0}\t{2:^10}'.format(
                count, move['title'], move['rate'], chr(12288)))
    url = 'https://movie.douban.com/j/search_subjects?type=movie&page_limit=20&sort=rank&' + \
        'tag=' + cate + '&' + data
    respones = urllib.request.urlopen(url=url)
    content = respones.read().decode('utf-8')
    my_json = json.loads(content)
    count = page*20
    for move in my_json['subjects'][0:remainder]:
        count += 1
        print('{0:^5}\t{1:{3}^３0}\t{2:^10}'.format(
            count, move['title'], move['rate'], chr(12288)))


def main():
    # get_tag()
    create_request(get_tag())


if __name__ == '__main__':
    main()
```

## habdler
HTTPHandler, 普通handler对象，可以配置一般请求
HTTPCookieProcessor,　配置cookie
HTTPProxyHandler, 配置代理

```python
import urllib.request
import urllib.parse

url = 'http://www.baidu.com'

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36',
}

req = urllib.request.Request(url=url, headers=headers)

# 构造更高级的请求对象
handler = urllib.request.HTTPHandler()
opener = urllib.request.build_opener(handler)
response = opener.open(req)

print(response.read().decode('utf-8'))
```

###人人网，登录
```python
import urllib.request
import urllib.parse
import http.cookiejar
import json


cookie = http.cookiejar.CookieJar()
handler = urllib.request.HTTPCookieProcessor(cookie)
opener = urllib.request.build_opener(handler)


post_url = 'http://www.renren.com/ajaxLogin/login?1=1&uniqueTimestamp=2019651354277'
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36',
}
form_data = {
    'email': '15620569943',
    'icode': '', 
    'origURL': 'http://www.renren.com/home',
    'domain': 'renren.com',
    'key_id': '1',
    'captcha_type': 'web_login',
    'password': '859a12c8d87dd25ee379ae206146390020d298612535bbb59cf29bacd5e2402e',
    'rkey': 'd0cf42c2d3d337f9e5d14083f2d52cb2',
    'f':'', 
}
# post做数据编码
data = urllib.parse.urlencode(form_data).encode('utf-8')
req = urllib.request.Request(data=data, url=post_url, headers=headers)
response = opener.open(req)

print(response.getcode())

my_url = 'http://www.renren.com/551403626/profile'
my_req = urllib.request.Request(url=my_url)
my_response = opener.open(my_req)
print(my_response.read().decode('utf-8'))
```

### Xpath语法

xpath 使用：
+安装lxml: pip install lxml
+导入：from lxml import etree
+使用：html_tree = etree.pares('html文件')　or html_tree = etree.HTML(response.read().decode('utf-8'))
